{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un5MOY7zyVzf",
        "outputId": "8e5c6737-4099-450e-89ff-a1f5c80e11c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.1.0.post1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ogb\n",
        "!pip install umap-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLSzJa5IydYA",
        "outputId": "051a63b3-5228-4c91-e2e4-78da016f4979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.12.1+cu113)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2022.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.7.3)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.5.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.64.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (4.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.49->umap-learn) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.49->umap-learn) (3.10.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Optional\n",
        "from torch_geometric.typing import Adj, OptTensor\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import ModuleList, Linear, BatchNorm1d\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, JumpingKnowledge\n",
        "from torch_geometric.data import NeighborSampler\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_sparse import SparseTensor"
      ],
      "metadata": {
        "id": "cYtRS9lyywmr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Logger(object):\n",
        "    def __init__(self, runs, info=None):\n",
        "        self.info = info\n",
        "        self.results = [[] for _ in range(runs)]\n",
        "\n",
        "    def add_result(self, run, result):\n",
        "        assert len(result) == 3\n",
        "        assert run >= 0 and run < len(self.results)\n",
        "        self.results[run].append(result)\n",
        "\n",
        "    def print_statistics(self, run=None, print_all=True):\n",
        "        if run is not None:\n",
        "            result = 100 * torch.tensor(self.results[run])\n",
        "            argmax = result[:, 1].argmax().item()\n",
        "            print(f'Run {run + 1:02d}:', flush=True)\n",
        "            print(f'Highest Train: {result[:, 0].max():.2f}', flush=True)\n",
        "            print(f'Highest Valid: {result[:, 1].max():.2f}', flush=True)\n",
        "            print(f'  Final Train: {result[argmax, 0]:.2f}', flush=True)\n",
        "            print(f'   Final Test: {result[argmax, 2]:.2f}', flush=True)\n",
        "        else:\n",
        "            result = 100 * torch.tensor(self.results)\n",
        "\n",
        "            best_results = []\n",
        "            for r in result:\n",
        "                train1 = r[:, 0].max().item()\n",
        "                valid = r[:, 1].max().item()\n",
        "                train2 = r[r[:, 1].argmax(), 0].item()\n",
        "                test = r[r[:, 1].argmax(), 2].item()\n",
        "                best_results.append((train1, valid, train2, test))\n",
        "\n",
        "            best_result = torch.tensor(best_results)\n",
        "\n",
        "            print(f'All runs:', flush=True)\n",
        "            if print_all:\n",
        "                r = best_result[:, 0]\n",
        "                print(f'Highest Train: {r.mean():.2f} ± {r.std():.2f}', flush=True)\n",
        "                r = best_result[:, 1]\n",
        "                print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}', flush=True)\n",
        "                r = best_result[:, 2]\n",
        "                print(f'  Final Train: {r.mean():.2f} ± {r.std():.2f}', flush=True)\n",
        "            r = best_result[:, 3]\n",
        "            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}', flush=True)"
      ],
      "metadata": {
        "id": "U8TODVofy9kS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelPropagation(MessagePassing):\n",
        "    def __init__(self, num_layers: int, alpha: float):\n",
        "        super(LabelPropagation, self).__init__(aggr='add')\n",
        "        self.num_layers = num_layers\n",
        "        self.alpha = alpha\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(\n",
        "            self, y: Tensor, edge_index: Adj, mask: Optional[Tensor] = None,\n",
        "            edge_weight: OptTensor = None,\n",
        "            post_step: Callable = lambda y: y.clamp_(0., 1.)\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\"\"\"\n",
        "\n",
        "        if y.dtype == torch.long:\n",
        "            y = F.one_hot(y.view(-1)).to(torch.float)\n",
        "\n",
        "        out = y\n",
        "        if mask is not None:\n",
        "            out = torch.zeros_like(y)\n",
        "            out[mask] = y[mask]\n",
        "\n",
        "        if isinstance(edge_index, SparseTensor) and not edge_index.has_value():\n",
        "            edge_index = gcn_norm(edge_index, add_self_loops=False)\n",
        "        elif isinstance(edge_index, Tensor) and edge_weight is None:\n",
        "            edge_index, edge_weight = gcn_norm(edge_index, num_nodes=y.size(0),\n",
        "                                               add_self_loops=False)\n",
        "\n",
        "        res = (1 - self.alpha) * out\n",
        "        for _ in range(self.num_layers):\n",
        "            # propagate_type: (y: Tensor, edge_weight: OptTensor)\n",
        "            out = self.propagate(edge_index, x=out, edge_weight=edge_weight,\n",
        "                                 size=None)\n",
        "            out.mul_(self.alpha).add_(res)\n",
        "            out = post_step(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        return matmul(adj_t, x, reduce=self.aggr)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}(num_layers={}, alpha={})'.format(self.__class__.__name__,\n",
        "                                                    self.num_layers,\n",
        "                                                    self.alpha)"
      ],
      "metadata": {
        "id": "iOISjdKWy-RK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CorrectAndSmooth(torch.nn.Module):\n",
        "    def __init__(self, num_correction_layers: int, correction_alpha: float,\n",
        "                 num_smoothing_layers: int, smoothing_alpha: float,\n",
        "                 autoscale: bool = True, scale: float = 1.0):\n",
        "        super(CorrectAndSmooth, self).__init__()\n",
        "        self.autoscale = autoscale\n",
        "        self.scale = scale\n",
        "\n",
        "        self.prop1 = LabelPropagation(num_correction_layers, correction_alpha)\n",
        "        self.prop2 = LabelPropagation(num_smoothing_layers, smoothing_alpha)\n",
        "\n",
        "    def correct(self, y_soft: Tensor, y_true: Tensor, mask: Tensor,\n",
        "                edge_index: Adj, edge_weight: OptTensor = None) -> Tensor:\n",
        "        assert abs((float(y_soft.sum()) / y_soft.size(0)) - 1.0) < 1e-2\n",
        "\n",
        "        numel = int(mask.sum()) if mask.dtype == torch.bool else mask.size(0)\n",
        "        assert y_true.size(0) == numel\n",
        "\n",
        "        if y_true.dtype == torch.long:\n",
        "            y_true = F.one_hot(y_true.view(-1), y_soft.size(-1))\n",
        "            y_true = y_true.to(y_soft.dtype)\n",
        "\n",
        "        error = torch.zeros_like(y_soft)\n",
        "        error[mask] = y_true - y_soft[mask]\n",
        "\n",
        "        if self.autoscale:\n",
        "            smoothed_error = self.prop1(error, edge_index,\n",
        "                                        edge_weight=edge_weight,\n",
        "                                        post_step=lambda x: x.clamp_(-1., 1.))\n",
        "\n",
        "            sigma = error[mask].abs().sum() / numel\n",
        "            scale = sigma / smoothed_error.abs().sum(dim=1, keepdim=True)\n",
        "            scale[scale.isinf() | (scale > 1000)] = 1.0\n",
        "            return y_soft + scale * smoothed_error\n",
        "        else:\n",
        "\n",
        "            def fix_input(x):\n",
        "                x[mask] = error[mask]\n",
        "                return x\n",
        "\n",
        "            smoothed_error = self.prop1(error, edge_index,\n",
        "                                        edge_weight=edge_weight,\n",
        "                                        post_step=fix_input)\n",
        "            return y_soft + self.scale * smoothed_error\n",
        "\n",
        "    def smooth(self, y_soft: Tensor, y_true: Tensor, mask: Tensor,\n",
        "               edge_index: Adj, edge_weight: OptTensor = None) -> Tensor:\n",
        "\n",
        "        numel = int(mask.sum()) if mask.dtype == torch.bool else mask.size(0)\n",
        "        assert y_true.size(0) == numel\n",
        "\n",
        "        if y_true.dtype == torch.long:\n",
        "            y_true = F.one_hot(y_true.view(-1), y_soft.size(-1))\n",
        "            y_true = y_true.to(y_soft.dtype)\n",
        "\n",
        "        y_soft[mask] = y_true\n",
        "\n",
        "        return self.prop2(y_soft, edge_index, edge_weight=edge_weight)\n",
        "\n",
        "    def __repr__(self):\n",
        "        L1, alpha1 = self.prop1.num_layers, self.prop1.alpha\n",
        "        L2, alpha2 = self.prop2.num_layers, self.prop2.alpha\n",
        "        return (f'{self.__class__.__name__}(\\n'\n",
        "                f'    correct: num_layers={L1}, alpha={alpha1}\\n'\n",
        "                f'    smooth:  num_layers={L2}, alpha={alpha2}\\n'\n",
        "                f'    autoscale={self.autoscale}, scale={self.scale}\\n'\n",
        "                ')')"
      ],
      "metadata": {
        "id": "Smm7nZvBzSy9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "y002j69azj-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PygNodePropPredDataset(name='ogbn-products', root='./products/')\n",
        "print(dataset, flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUW_gFPOzXWa",
        "outputId": "4b36c8cb-0fad-4467-b118-c19842660d2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PygNodePropPredDataset()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]\n",
        "print(data, flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhMapPauzpBC",
        "outputId": "ff210d7b-c8b2-49bd-f2d8-be719cb3cc1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(num_nodes=2449029, edge_index=[2, 123718280], x=[2449029, 100], y=[2449029, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split_idx contains a dictionary of train, validation and test node indices\n",
        "split_idx = dataset.get_idx_split()\n",
        "# predefined ogb evaluator method used for validation of predictions\n",
        "evaluator = Evaluator(name='ogbn-products')"
      ],
      "metadata": {
        "id": "WVm3raIFzrHa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets check the node ids distribution of train, test and val\n",
        "print('Number of training nodes:', split_idx['train'].size(0))\n",
        "print('Number of validation nodes:', split_idx['valid'].size(0))\n",
        "print('Number of test nodes:', split_idx['test'].size(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWRvIk3G0s62",
        "outputId": "85b3de04-1566-4533-931d-8dc951087af8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training nodes: 196615\n",
            "Number of validation nodes: 39323\n",
            "Number of test nodes: 2213091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets check some graph statistics of ogb-product graph\n",
        "print(\"Number of nodes in the graph:\", data.num_nodes)\n",
        "print(\"Number of edges in the graph:\", data.num_edges)\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"Node feature matrix with shape:\", data.x.shape) # [num_nodes, num_node_features]\n",
        "print(\"Graph connectivity in COO format with shape:\", data.edge_index.shape) # [2, num_edges]\n",
        "print(\"Target to train against :\", data.y.shape) \n",
        "print(\"Node feature length\", dataset.num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzTT8Lwl0vzO",
        "outputId": "cf69f655-ac6b-474e-cfa2-5ec7bf8027e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes in the graph: 2449029\n",
            "Number of edges in the graph: 123718280\n",
            "---------------------------------------------\n",
            "Node feature matrix with shape: torch.Size([2449029, 100])\n",
            "Graph connectivity in COO format with shape: torch.Size([2, 123718280])\n",
            "Target to train against : torch.Size([2449029, 1])\n",
            "Node feature length 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx = split_idx['train']\n",
        "test_idx = split_idx['test']"
      ],
      "metadata": {
        "id": "Fqs_0PKn0yeD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = NeighborSampler(data.edge_index, node_idx=train_idx,\n",
        "                               sizes=[15, 10, 5], batch_size=1024,\n",
        "                               shuffle=True, num_workers=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8O_oJqO04qF",
        "outputId": "c9e8038c-1de4-4700-c781-a89e7ac2e97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.NeighborSampler' is deprecated, use 'loader.NeighborSampler' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subgraph_loader = NeighborSampler(data.edge_index, node_idx=None, sizes=[-1],\n",
        "                                  batch_size=1024, shuffle=False,\n",
        "                                  num_workers=12)"
      ],
      "metadata": {
        "id": "FWhQOzN607WW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, dataset, hidden_channels, num_layers=3):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "\n",
        "        self.convs.append(SAGEConv(dataset.num_node_features, hidden_channels))\n",
        "        self.bns.append(nn.BatchNorm1d(hidden_channels))\n",
        "\n",
        "        for i in range(self.num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "            self.bns.append(nn.BatchNorm1d(hidden_channels))\n",
        "\n",
        "        self.convs.append(SAGEConv(hidden_channels, dataset.num_classes))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        # `train_loader` computes the k-hop neighborhood of a batch of nodes,\n",
        "        # and returns, for each layer, a bipartite graph object, holding the\n",
        "        # bipartite edges `edge_index`, the index `e_id` of the original edges,\n",
        "        # and the size/shape `size` of the bipartite graph.\n",
        "        # Target nodes are also included in the source nodes so that one can\n",
        "        # easily apply skip-connections or add self-loops.\n",
        "        for i, (adj_t, _, size) in enumerate(adjs):\n",
        "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
        "            x = self.convs[i]((x, x_target), adj_t)\n",
        "            # x = x + self.skips[i](x_target)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = self.bns[i](x)\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "\n",
        "        # Compute representations of nodes layer by layer, using *all*\n",
        "        # available edges. This leads to faster computation in contrast to\n",
        "        # immediately computing the final representations of each batch.\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in subgraph_loader:\n",
        "                adj_t, _, size = adj.to(device)\n",
        "                total_edges += adj_t.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), adj_t)\n",
        "                # x = x + self.skips[i](x_target)\n",
        "\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = self.bns[i](x)\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x.cpu())\n",
        "\n",
        "                pbar.update(batch_size)\n",
        "\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        return x_all"
      ],
      "metadata": {
        "id": "3O7pOd4L1Qx7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SAGE(dataset=dataset, hidden_channels=256, num_layers=3)\n",
        "print(model, flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNRvADVM1XKL",
        "outputId": "eed80f20-af7a-4654-8a0c-1bd0b75514ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAGE(\n",
            "  (convs): ModuleList(\n",
            "    (0): SAGEConv(100, 256, aggr=mean)\n",
            "    (1): SAGEConv(256, 256, aggr=mean)\n",
            "    (2): SAGEConv(256, 47, aggr=mean)\n",
            "  )\n",
            "  (bns): ModuleList(\n",
            "    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device, flush=True)\n",
        "model.to(device)\n",
        "data = data.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgF2Ffof1ZVq",
        "outputId": "d546addd-8c27-4c10-d7f4-0888fa0869a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = data.x.to(device), data.y.squeeze().to(device)\n",
        "train_idx = split_idx['train'].to(device)\n",
        "val_idx = split_idx['valid'].to(device)\n",
        "test_idx = split_idx['test'].to(device)\n",
        "x_train, y_train = x[train_idx], y[train_idx]"
      ],
      "metadata": {
        "id": "os0Fk5pQ1hKn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_adj(data):\n",
        "    N = data.num_nodes\n",
        "    data.edge_index = to_undirected(data.edge_index, data.num_nodes)\n",
        "\n",
        "    row, col = data.edge_index\n",
        "\n",
        "    adj = SparseTensor(row=row, col=col, sparse_sizes=(N, N))\n",
        "    adj = adj.set_diag()\n",
        "    deg = adj.sum(dim=1).to(torch.float)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "    adj = deg_inv_sqrt.view(-1, 1) * adj * deg_inv_sqrt.view(1, -1)\n",
        "    return adj"
      ],
      "metadata": {
        "id": "eRvHWSyZ1jgS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DAD = process_adj(data).to(device)"
      ],
      "metadata": {
        "id": "lMWGFxsa1mP3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "metadata": {
        "id": "cXWQkTKq1n5w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    pbar = tqdm(total=train_idx.size(0))\n",
        "    pbar.set_description(f'Epoch {epoch:02d}')\n",
        "\n",
        "    total_loss = total_correct = 0\n",
        "    for batch_size, n_id, adjs in train_loader:\n",
        "        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
        "        adjs = [adj.to(device) for adj in adjs]\n",
        "\n",
        "        out = model(x[n_id], adjs)\n",
        "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n",
        "        pbar.update(batch_size)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    loss = total_loss / len(train_loader)\n",
        "    approx_acc = total_correct / int(train_idx.size(0))\n",
        "\n",
        "    return loss, approx_acc"
      ],
      "metadata": {
        "id": "brgeqdDi1pzX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(out=None):\n",
        "    model.eval()\n",
        "\n",
        "    out = model.inference(x) if out is None else out\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc, out"
      ],
      "metadata": {
        "id": "LIZraCwz1scs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    runs = 2\n",
        "    logger = Logger(runs)\n",
        "\n",
        "    for run in range(runs):\n",
        "        print(sum(p.numel() for p in model.parameters()), flush=True)\n",
        "\n",
        "        print('', flush=True)\n",
        "        print(f'Run {run + 1:02d}:', flush=True)\n",
        "        print('', flush=True)\n",
        "\n",
        "        model.reset_parameters()\n",
        "\n",
        "        best_val_acc = 0\n",
        "\n",
        "        for epoch in range(10):\n",
        "            loss, acc = train()\n",
        "            # print('Epoch {:03d} train_loss: {:.4f}'.format(epoch, loss))\n",
        "            print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}', flush=True)\n",
        "\n",
        "            if (epoch + 1) > 5:\n",
        "\n",
        "                train_acc, val_acc, test_acc, out = test()\n",
        "                result = (train_acc, val_acc, test_acc)\n",
        "                # print(f'Train: {train_acc:.4f}, Val: {valid_acc:.4f}, 'f'Test: {test_acc:.4f}')\n",
        "                if val_acc > best_val_acc:\n",
        "                    best_val_acc = val_acc\n",
        "                    y_soft = out.softmax(dim=-1).to(device)\n",
        "\n",
        "                print(f'Run: {run + 1:02d}, '\n",
        "                      f'Epoch: {epoch:02d}, '\n",
        "                      f'Loss: {loss:.4f}, '\n",
        "                      f'Train: {100 * train_acc:.2f}%, '\n",
        "                      f'Valid: {100 * val_acc:.2f}% '\n",
        "                      f'Test: {100 * test_acc:.2f}%', flush=True)\n",
        "\n",
        "        post = CorrectAndSmooth(num_correction_layers=100, correction_alpha=0.8,\n",
        "                                num_smoothing_layers=100, smoothing_alpha=0.8,\n",
        "                                autoscale=False, scale=10.)\n",
        "\n",
        "        print('Correct and smooth...', flush=True)\n",
        "\n",
        "        y_soft = post.correct(y_soft, y_train, train_idx, DAD)\n",
        "        y_soft = post.smooth(y_soft, y_train, train_idx, DAD)\n",
        "        print('Done!', flush=True)\n",
        "        \n",
        "        train_acc, val_acc, test_acc, _ = test(y_soft)        \n",
        "        print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}', flush=True)\n",
        "\n",
        "        result = (train_acc, val_acc, test_acc)\n",
        "        logger.add_result(run, result)\n",
        "\n",
        "    logger.print_statistics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJVx80qh1tUi",
        "outputId": "bc076e43-7bbc-420f-9393-680b42ee409d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207919\n",
            "\n",
            "Run 01:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 00: 100%|██████████| 196615/196615 [00:47<00:00, 4158.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00, Loss: 0.5680, Approx. Train: 0.8522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 01: 100%|██████████| 196615/196615 [00:47<00:00, 4147.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01, Loss: 0.3684, Approx. Train: 0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 02: 100%|██████████| 196615/196615 [00:47<00:00, 4139.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02, Loss: 0.3535, Approx. Train: 0.9025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 03: 100%|██████████| 196615/196615 [00:47<00:00, 4122.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03, Loss: 0.3466, Approx. Train: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 04: 100%|██████████| 196615/196615 [00:47<00:00, 4126.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04, Loss: 0.3238, Approx. Train: 0.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 05: 100%|██████████| 196615/196615 [00:47<00:00, 4135.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05, Loss: 0.3185, Approx. Train: 0.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:33<00:00, 47957.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 05, Loss: 0.3185, Train: 92.44%, Valid: 91.53% Test: 78.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 06: 100%|██████████| 196615/196615 [00:47<00:00, 4111.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06, Loss: 0.2996, Approx. Train: 0.9148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:28<00:00, 49356.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 06, Loss: 0.2996, Train: 92.80%, Valid: 91.47% Test: 79.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 07: 100%|██████████| 196615/196615 [00:47<00:00, 4097.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07, Loss: 0.3027, Approx. Train: 0.9138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:22<00:00, 51509.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 07, Loss: 0.3027, Train: 92.97%, Valid: 91.75% Test: 78.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 08: 100%|██████████| 196615/196615 [00:48<00:00, 4078.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08, Loss: 0.2996, Approx. Train: 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:29<00:00, 49082.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 08, Loss: 0.2996, Train: 92.77%, Valid: 91.50% Test: 77.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 09: 100%|██████████| 196615/196615 [00:47<00:00, 4098.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09, Loss: 0.2963, Approx. Train: 0.9166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:22<00:00, 51533.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 01, Epoch: 09, Loss: 0.2963, Train: 92.98%, Valid: 91.67% Test: 78.46%\n",
            "Correct and smooth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n",
            "Train: 0.9720, Val: 0.9221, Test: 0.8041\n",
            "207919\n",
            "\n",
            "Run 02:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 00: 100%|██████████| 196615/196615 [00:48<00:00, 4053.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00, Loss: 0.5707, Approx. Train: 0.8530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 01: 100%|██████████| 196615/196615 [00:47<00:00, 4096.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01, Loss: 0.3882, Approx. Train: 0.8939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 02: 100%|██████████| 196615/196615 [00:48<00:00, 4072.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02, Loss: 0.3637, Approx. Train: 0.9008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 03: 100%|██████████| 196615/196615 [00:48<00:00, 4087.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03, Loss: 0.3531, Approx. Train: 0.9006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 04: 100%|██████████| 196615/196615 [00:48<00:00, 4074.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04, Loss: 0.3354, Approx. Train: 0.9076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 05: 100%|██████████| 196615/196615 [00:48<00:00, 4065.86it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05, Loss: 0.3334, Approx. Train: 0.9059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:28<00:00, 49540.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 02, Epoch: 05, Loss: 0.3334, Train: 92.30%, Valid: 91.25% Test: 77.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 06: 100%|██████████| 196615/196615 [00:48<00:00, 4075.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06, Loss: 0.3138, Approx. Train: 0.9119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:24<00:00, 50906.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 02, Epoch: 06, Loss: 0.3138, Train: 92.50%, Valid: 91.46% Test: 77.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 07: 100%|██████████| 196615/196615 [00:48<00:00, 4071.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07, Loss: 0.3143, Approx. Train: 0.9114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:30<00:00, 48854.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 02, Epoch: 07, Loss: 0.3143, Train: 92.47%, Valid: 91.32% Test: 76.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 08: 100%|██████████| 196615/196615 [00:48<00:00, 4039.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08, Loss: 0.3255, Approx. Train: 0.9086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:24<00:00, 50920.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 02, Epoch: 08, Loss: 0.3255, Train: 92.69%, Valid: 91.46% Test: 77.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 09: 100%|██████████| 196615/196615 [00:48<00:00, 4081.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09, Loss: 0.3159, Approx. Train: 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating: 100%|██████████| 7347087/7347087 [02:32<00:00, 48245.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 02, Epoch: 09, Loss: 0.3159, Train: 92.70%, Valid: 91.66% Test: 78.72%\n",
            "Correct and smooth...\n",
            "Done!\n",
            "Train: 0.9729, Val: 0.9231, Test: 0.8040\n",
            "All runs:\n",
            "Highest Train: 97.25 ± 0.06\n",
            "Highest Valid: 92.26 ± 0.07\n",
            "  Final Train: 97.25 ± 0.06\n",
            "   Final Test: 80.40 ± 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wn_wIiEyMAdm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}